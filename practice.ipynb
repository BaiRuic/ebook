{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input, kernel, bias, stride, padding):\n",
    "    if padding > 0:\n",
    "        input = np.pad(input, \n",
    "                        ((0, 0), (0, 0), (padding, padding), (padding, padding)), \n",
    "                        \"constant\", \n",
    "                        constant_values=0)\n",
    "    batch_size, in_channel, x_h, x_w=  input.shape\n",
    "    out_channel, in_channel, k_h, k_w = kernel.shape\n",
    "    \n",
    "    y_h = (x_h - k_h) // stride + 1\n",
    "    y_w = (x_w - k_w) // stride + 1\n",
    "    output = np.zeros((batch_size, out_channel, y_h, y_w))  \n",
    "\n",
    "    for bs in range(batch_size):\n",
    "        for oc in range(out_channel):\n",
    "            output[bs][oc] += bias[oc]\n",
    "            for ic in range(in_channel):\n",
    "                for i in range(0, x_h-k_h+1, stride):\n",
    "                    for j in range(0, x_w-k_w+1, stride):\n",
    "                        region = input[bs, ic, i:i+k_h, j:j+k_w]\n",
    "                        \n",
    "                        output[bs, oc, int(i//stride), int(j //)] += np.sum(region * kernel[oc, ic])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 5, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(128, 3, 5,5)\n",
    "kernel = np.random.randn(5, 3, 3, 3)\n",
    "bias = np.random.randn(5)\n",
    "y = conv2d(x, kernel, bias, 1, 0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, seq_len):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            in_feature：输入维度\n",
    "            out_feature：输出维度\n",
    "            seq_len: 序列长度\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        self.lstm = nn.LSTM(in_feature, out_feature, 2)\n",
    "\n",
    "        # 每个时刻适用不同的线性模型\n",
    "        self.out = nn.Sequential()\n",
    "        for i in range(seq_len):\n",
    "            self.out.add_module(name=\"t\" + str(i), \n",
    "                                module = nn.Linear(out_feature, 1))\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        seq_len, batch_szie, in_feature = x.shape\n",
    "\n",
    "        x_1, _ = self.lstm(x)   \n",
    "        a, b, c = x_1.shape  # [seq_len, batch_size, out_feature]\n",
    "\n",
    "        # 对每个时刻进行转换\n",
    "        outputs = torch.zeros((seq_len, batch_szie, 1))\n",
    "        for i in range(seq_len):\n",
    "            outputs[i,:,:] = self.out[i](x_1[i, :, :])\n",
    "            \n",
    "        return outputs\n",
    "\n",
    "rnn = RNN(in_feature=8, out_feature=16, seq_len=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(14, 1, 8)\n",
    "x = torch.from_numpy(x).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = rnn(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, K, stride, bias, padding):\n",
    "\n",
    "    X = np.pad(array=X, \n",
    "                pad_width=((0, 0), (0, 0), (padding, padding), (padding, padding)),\n",
    "                mod='constant', \n",
    "                constant_values=0)\n",
    "\n",
    "    batch_size, x_in, x_h, x_w = X.shape\n",
    "    out_channel, in_channel, k_h, k_w = K.shape\n",
    "    assert x_in == in_channel, \"维度不匹配\"\n",
    "    \n",
    "    y_h = (x_h - k_h) // stride + 1\n",
    "    y_w = (x_w - k_w) // stride + 1\n",
    "    \n",
    "    Y = np.zeros((batch_size, out_channel, y_h, y_w))\n",
    "\n",
    "    if bias is None:\n",
    "        bias = np.zeros(( out_channel))\n",
    "\n",
    "    for bs in range(batch_size):\n",
    "        for oc in range(out_channel):\n",
    "            Y[:, oc, :, :] += bias[oc]\n",
    "            for ic in range(in_channel):\n",
    "                for i in range(0, x_h-k_h+1, stride):\n",
    "                    for j in range(0, x_w-k_w+1, stride):\n",
    "                        region = X[bs, ic, i:i+k_h, j:j+k_w]\n",
    "                        kernel = K[oc, ic]\n",
    "                        Y[bs, oc, int(i//stride), int(j//stride)] += np.sum(region * kernel)\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def matrix_matual(A, B) -> List[List[int]]:\n",
    "    m, n = len(A), len(A[0])\n",
    "    t, q = len(B), len(B[0])\n",
    "\n",
    "    assert n == t, \"维度不匹配\"\n",
    "    \n",
    "    res = [[0] * q for _ in range(m)]\n",
    "\n",
    "    for i in range(0, m):\n",
    "        for j in range(0, q):\n",
    "            for k in range(0, n):\n",
    "                res[i][j] += A[i][k] * B[k][j]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2187,  854, 2147, 1793, 1988],\n",
       "        [4190, 2372, 3833, 3067, 3638],\n",
       "        [3383, 1568, 2542, 2316, 2613]]),\n",
       " [[2187, 854, 2147, 1793, 1988],\n",
       "  [4190, 2372, 3833, 3067, 3638],\n",
       "  [3383, 1568, 2542, 2316, 2613]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.random.randint(0, 20, (3, 8))\n",
    "B = np.random.randint(0, 70, (8, 5))\n",
    "\n",
    "res_np = np.matmul(A, B)\n",
    "res_my = matrix_matual(A.tolist(), B.tolist())\n",
    "\n",
    "res_np, res_my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil(5/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, *arg, **kwarg):\n",
    "        return self.forward(*arg, **kwarg)\n",
    "\n",
    "    def forward(self, *arg, **kwarg):\n",
    "        pass\n",
    "    \n",
    "    def backwarg(self, *arg, **kwarg):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(Module):\n",
    "    def __init__(self, out_channel, in_channel, k_w, k_h, stride, padding):\n",
    "        self.out_channel = out_channel\n",
    "        self.in_channel = in_channel\n",
    "        self.k_h = k_h\n",
    "        self.k_w = k_w\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self._init_params()\n",
    "        \n",
    "\n",
    "    def _init_params(self):\n",
    "        self.K = np.random.normal((self.out_channel, self.in_channel, self.k_h, self.k_w))\n",
    "        self.bias = np.random.random((self.out_channel))\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self._conv2d(X, self.K, self.bias, self.stride, self.padding)\n",
    "        \n",
    "    \n",
    "    def _conv2d(self, X, K, bias, stride, padding):\n",
    "        X = np.pad(array=X, \n",
    "                    pad_width=((0, 0), (0, 0), (padding, padding), (padding, padding)),\n",
    "                    mod='constant', \n",
    "                    constant_values=0)\n",
    "\n",
    "        batch_size, x_in, x_h, x_w = X.shape\n",
    "        out_channel, in_channel, k_h, k_w = K.shape\n",
    "        assert x_in == in_channel, \"维度不匹配\"\n",
    "        \n",
    "        y_h = (x_h - k_h) // stride + 1\n",
    "        y_w = (x_w - k_w) // stride + 1\n",
    "        \n",
    "        Y = np.zeros((batch_size, out_channel, y_h, y_w))\n",
    "\n",
    "        if bias is None:\n",
    "            bias = np.zeros(( out_channel))\n",
    "\n",
    "        for bs in range(batch_size):\n",
    "            for oc in range(out_channel):\n",
    "                Y[:, oc, :, :] += bias[oc]\n",
    "                for ic in range(in_channel):\n",
    "                    for i in range(0, x_h-k_h+1, stride):\n",
    "                        for j in range(0, x_w-k_w+1, stride):\n",
    "                            region = X[bs, ic, i:i+k_h, j:j+k_w]\n",
    "                            kernel = K[oc, ic]\n",
    "                            Y[bs, oc, int(i//stride), int(j//stride)] += np.sum(region * kernel)\n",
    "\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(input_, init_h, W_hx, W_hh, b):\n",
    "    \"\"\" input_ :[batch_size, seq_len, input_size]\n",
    "        init_h: 初始 状态向量 h [batch_size, output_size]\n",
    "        W_hx: 参数矩阵    [input_size, output_size]\n",
    "        W_hh: 参数矩阵    [output_size, output_size]\n",
    "        b: 偏置参数\n",
    "    \"\"\"\n",
    "    output_size, _ = W_hh.shape\n",
    "    batch_size, seq_len, input_size = input_.shape\n",
    "    outputs = np.zeros((batch_size, seq_len, output_size))\n",
    "\n",
    "    prev_h = init_h\n",
    "    for i in range(0, seq_len):\n",
    "        cur_x = input_[:, i:, :]\n",
    "        cur_h = np.tanh(W_hh @  prev_h + W_hx @ cur_x + b)\n",
    "        \n",
    "        outputs[:, :, :] = cur_h\n",
    "        prev_h = cur_h\n",
    "\n",
    "    return outputs, cur_h.reshape(1, batch_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class RNNCell:\n",
    "    def __init__(self, input_size, hidden_size, bias, nonlinearity='tanh'):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "            input_size: The number of expected features in the input x\n",
    "            hidden_size: The number of features in the hidden state h\n",
    "            bias: If False, then the layer does not use bias weights b. Default: True\n",
    "            nonlinearity: The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'\n",
    "        \"\"\"\n",
    "        # init_param \n",
    "        self.W_hh = np.random.normal(loc=0, scale=np.sqrt(1/hidden_size))\n",
    "        self.W_hx = np.random.normal(loc=0, scale=np.sqrt(2/(input_size+hidden_size)))\n",
    "        self.bias = bias\n",
    "        if self.bias:\n",
    "            self.b = np.zeros((hidden_size))\n",
    "        self.nonlinearity = nonlinearity\n",
    "\n",
    "\n",
    "    def forward(self, x, prev_h):\n",
    "        \"\"\"input_ :[batch_size, input_size]\n",
    "        \"\"\"\n",
    "        a = prev_h @ self.W_hh + x @ self.W_hx\n",
    "        if self.bias:\n",
    "            a += self.b\n",
    "        if self.nonlinearity == \"tanh\":\n",
    "            a = np.tanh(a)\n",
    "        elif self.nonlinearity == \"relu\":\n",
    "            a = self.relu(a)\n",
    "        return a\n",
    "\n",
    "\n",
    "    def __call__(self, *arg):\n",
    "        return self.forward(*arg)     \n",
    "\n",
    "    def backward(self, pre_grad):\n",
    "        pass\n",
    "\n",
    "    def relu(self, x):\n",
    "        mask = x < 0\n",
    "        x[mask] = 0\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_size, hidden_size, bias, nonlinearity):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.cell = RNNCell(self.input_size, self.hidden_size, bias, nonlinearity)\n",
    "        \n",
    "    def forward(self, input_, prev_h):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "            input_ :[batch_size, seq_len, input_size]\n",
    "            prev_h: [batch_size, seq_len, hidden_size]\n",
    "        return :\n",
    "            outputs: [batch_size, seq_len, hidden_size]\n",
    "            cur_h: [1, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, input_size = input_.shape\n",
    "\n",
    "        outputs = np.zeros((batch_size, seq_len, self.hidden_size))\n",
    "\n",
    "        for i in range(0, seq_len):\n",
    "            cur_x = input_[:, i, :]\n",
    "            cur_h = self.cell(cur_x, prev_h)\n",
    "            \n",
    "            outputs[:, i, :] = cur_h\n",
    "            prev_h = cur_h\n",
    "\n",
    "        return outputs, cur_h.reshape(1, batch_size, self.hidden_size)  \n",
    "\n",
    "    def __call__(self, *arg):\n",
    "        return self.forward(*arg)\n",
    "\n",
    "    def backward(self, pre_grad):\n",
    "        pass      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  6, -6,  5],\n",
       "       [ 8,  9, -9,  8],\n",
       "       [-2,  7,  9,  5],\n",
       "       [-5, -8, -4, -5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(-10, 10, size=(4, 4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = x < 0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 6, 0, 5],\n",
       "       [8, 9, 0, 8],\n",
       "       [0, 7, 9, 5],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[mask] = 0 \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def conv2d(X, K, b):\n",
    "    \"\"\"\n",
    "    X: 输入特征图, shape:[x_w, x_h]\n",
    "    K: 卷积核, shape:[k_w, k_h]\n",
    "    \"\"\"\n",
    "    x_w, x_h = X.shape\n",
    "    k_w, k_h = K.shape\n",
    "    \n",
    "    # 输出特征图大小\n",
    "    y_w, y_h = x_w - k_w + 1, x_h-k_h+1\n",
    "    Y = np.zeros((y_w, y_h))\n",
    "    \n",
    "    # 计算输出特征图的每个值\n",
    "    for i in range(0, y_h):\n",
    "        for j in range(0, y_w):\n",
    "            conv_region = X[i:i+k_h, j:j+k_w]\n",
    "            Y[i, j] = np.sum(conv_region * K) + b\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, K, b, stride, padding):\n",
    "    \"\"\"\n",
    "    X: 输入特征图, shape:[x_w, x_h]\n",
    "    K: 卷积核, shape:[k_w, k_h]\n",
    "    \"\"\"\n",
    "    # 填充\n",
    "    if padding > 0:\n",
    "        X  =np.pad(array=X, \n",
    "                    pad_width=((padding, padding), (padding, padding)),\n",
    "                    mode=\"constant\",\n",
    "                    condtant_values = 0)\n",
    "    \n",
    "    x_h, x_w = X.shape\n",
    "    k_h, k_w = K.shape\n",
    "\n",
    "    y_h = (x_h - k_h) // stride + 1\n",
    "    y_w = (x_w - k_w) // stride + 1\n",
    "    \n",
    "    Y = np.zeros((y_h, y_w))\n",
    "    \n",
    "    for i in range(0, x_h-y_w+1, stride):\n",
    "        for j in range(x_w-k_w+1, stride):\n",
    "            conv_region = X[i:i+k_h, j:j+k_w]\n",
    "            Y[i//stride][j//stride]  = np.sum(conv_region * K) + b\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2d(X, K, bias, stride, paddind):\n",
    "    batch_size, in_channel, x_h, x_w = X.shape\n",
    "    out_channel, in_channel, k_h, k_w = K.shape\n",
    "    \n",
    "    y_h = (x_h-k_h) // stride + 1\n",
    "    y_w = (x_w-k_w) // stride + 1\n",
    "\n",
    "    Y = np.zeros((batch_size, out_channel, y_h, y_w))\n",
    "    for b_s in range(0, batch_size):\n",
    "        for o_c in range(0, out_channel):\n",
    "            Y[b_s, o_c] += bias[oc]\n",
    "            for i_c in range(0, in_channel):\n",
    "                for i in range(0, x_h-k_h+1, stride):\n",
    "                    for j in range(0, x_w-k_w+1, stride):\n",
    "                        conv_region = X[b_s, i_c, i:i+k_h, j:j+k_h]\n",
    "                        Y[b_s, o_c, i//stride, j//stride] += np.sum(conv_region * K[o_c, i_c])\n",
    "            \n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kenel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.bias = bias\n",
    "\n",
    "        self.kernel = np.random.normal((self.out_channels, self.in_channels, *self.kernel_size))\n",
    "        self.b = np.zeros((self.out_channels)) if self.bias else None\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self._conv2d(X, self.kernel, self.b, self.stride, self.padding)\n",
    "\n",
    "    def backward(self, pre_grad):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, *arg):\n",
    "        return self.forward(*arg)\n",
    "\n",
    "\n",
    "    def _conv2d(self, X, K, b, stride, padding):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv2d(self, X, K, b, stride, padding):\n",
    "    \"\"\"\n",
    "    param:\n",
    "        X: 输入特征图 \n",
    "            type: np.array\n",
    "            shape: [batch_size, in_channels, x_h, x_w]\n",
    "        K: 卷积核 \n",
    "            type: np.array\n",
    "            shape: [out_channels, in_channels, k_h, k_w]\n",
    "        stride: 卷积步长\n",
    "        padding: padding\n",
    "    \"\"\"\n",
    "    if padding > 0:\n",
    "        X  =np.pad(array=X, \n",
    "                    pad_width=((0, 0), (0, 0),(padding, padding), (padding, padding)),\n",
    "                    mode=\"constant\",\n",
    "                    condtant_values = 0)\n",
    "\n",
    "        batch_size, in_channels_x, x_h, x_w = X.shape\n",
    "        out_channels, in_channels_k, k_h, k_w = K.shape\n",
    "\n",
    "        assert in_channels_x == in_channels_k, \"输入特征图和卷积核维度不匹配\"\n",
    "\n",
    "        y_h = (x_h - k_h) // stride + 1\n",
    "        y_w = (x_w - k_w) // stride + 1\n",
    "\n",
    "        if b is None:\n",
    "            b = np.zeros((out_channels))\n",
    "        \n",
    "        Y = np.zeros((batch_size, out_channels, y_h, y_w))\n",
    "\n",
    "        for b_s in range(0, batch_size):\n",
    "            for o_c in range(0, out_channels):\n",
    "                Y[b_s, o_c] += b[o_c]\n",
    "                for i_c in range(0, in_channels_k):\n",
    "                    for i in range(0,x_h-k_h+1 , stride):\n",
    "                        for j in range(0,x_w-k_w+1 ,stride):\n",
    "                            conv_region = X[b_s, i_c, i:i+k_h, j:j+k_w]\n",
    "                            Y[b_s, o_c, i//stride, j//stride] = np.sum(conv_region * K[o_c, i_c])\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = np.random.randint(0, 3, (3, 4, 5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[2, 0, 0, 1, 1],\n",
       "         [0, 1, 2, 0, 2],\n",
       "         [0, 0, 0, 1, 2],\n",
       "         [0, 0, 0, 2, 0],\n",
       "         [1, 0, 0, 2, 2]],\n",
       "\n",
       "        [[1, 1, 0, 0, 2],\n",
       "         [1, 1, 0, 0, 1],\n",
       "         [0, 2, 0, 2, 1],\n",
       "         [1, 0, 0, 1, 2],\n",
       "         [2, 0, 0, 0, 0]],\n",
       "\n",
       "        [[1, 0, 1, 0, 2],\n",
       "         [1, 0, 2, 2, 1],\n",
       "         [1, 0, 1, 1, 1],\n",
       "         [0, 2, 2, 0, 0],\n",
       "         [2, 1, 0, 2, 2]],\n",
       "\n",
       "        [[2, 0, 2, 2, 2],\n",
       "         [0, 1, 2, 2, 1],\n",
       "         [1, 2, 1, 1, 0],\n",
       "         [0, 0, 2, 0, 1],\n",
       "         [0, 2, 1, 0, 1]]],\n",
       "\n",
       "\n",
       "       [[[0, 1, 2, 2, 0],\n",
       "         [1, 1, 1, 1, 2],\n",
       "         [0, 2, 2, 2, 0],\n",
       "         [2, 0, 1, 1, 1],\n",
       "         [2, 0, 1, 1, 0]],\n",
       "\n",
       "        [[2, 1, 2, 1, 0],\n",
       "         [2, 2, 0, 1, 0],\n",
       "         [1, 0, 1, 2, 2],\n",
       "         [2, 1, 0, 1, 2],\n",
       "         [2, 0, 1, 1, 1]],\n",
       "\n",
       "        [[0, 2, 2, 2, 1],\n",
       "         [0, 1, 1, 0, 1],\n",
       "         [2, 2, 1, 1, 2],\n",
       "         [0, 2, 0, 0, 0],\n",
       "         [1, 0, 0, 2, 1]],\n",
       "\n",
       "        [[1, 0, 2, 0, 1],\n",
       "         [1, 1, 1, 2, 0],\n",
       "         [0, 0, 2, 2, 1],\n",
       "         [2, 0, 2, 0, 0],\n",
       "         [2, 0, 0, 1, 2]]],\n",
       "\n",
       "\n",
       "       [[[0, 2, 1, 0, 2],\n",
       "         [1, 2, 2, 1, 0],\n",
       "         [2, 1, 0, 2, 0],\n",
       "         [1, 0, 2, 2, 0],\n",
       "         [0, 2, 2, 0, 1]],\n",
       "\n",
       "        [[1, 0, 0, 0, 2],\n",
       "         [0, 0, 0, 1, 2],\n",
       "         [1, 1, 0, 0, 2],\n",
       "         [1, 1, 1, 2, 1],\n",
       "         [0, 2, 2, 0, 0]],\n",
       "\n",
       "        [[0, 1, 1, 2, 0],\n",
       "         [1, 1, 1, 2, 1],\n",
       "         [0, 2, 0, 2, 0],\n",
       "         [2, 0, 1, 0, 1],\n",
       "         [0, 1, 2, 0, 2]],\n",
       "\n",
       "        [[1, 0, 2, 1, 0],\n",
       "         [1, 0, 0, 2, 2],\n",
       "         [1, 0, 1, 1, 1],\n",
       "         [2, 1, 2, 0, 0],\n",
       "         [2, 1, 1, 0, 2]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 1],\n",
       "       [2, 1],\n",
       "       [1, 1],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2, 3, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "820d776940a02930c69820a8cec178404e4e9e60b6116e2717a21913b50566a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
