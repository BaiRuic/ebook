{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传统的Seq2Seq模型包含两部分，一部分叫编码器，另一部分叫解码器。\n",
    "把原序列送入编码器之中，得到固定的向量表征，通常是编码器的最后一个隐藏状态作为整个原序列固定的表征，解码器就基于这个固定的表征来生成目标序列。\n",
    "\n",
    "它利用编码器得到的是一个固定大小的表征向量，这里就隐含一个假设，它假设编码器能够将输入序列所有的信息压缩到这个固定长度的向量中，那对于较长的序列，显然是很困难的，即这个假设很难成立。\n",
    "\n",
    "为了解决这个问题，15年有人提出了基于attention机制的seq2seq模型。编码器不再是输出一个固定大小的向量了，而是输出与输入序列等长的一组向量，然后decoder也不再使用固定的向量作为输入了，而是每次生成一个预测值的时候，都会去编码器生成的这一组向量中挑选相关度最高的向量作为输入。 \n",
    "\n",
    "每次预测，都会通过上一个预测输出和编码器输出的一组向量生成 一个新的隐藏状态 c_i 作为当前lstm单元的输入：\n",
    "\n",
    "$$c_i = \\sum_{j=1}^{T_x} a_{ij}h_j$$\n",
    "$h_{j:T_x}$为编码器生成的一组向量，$a_{ij}$为注意力分布,为第i时刻对整个编码器输出向量h_j的注意力分数，计算方式如下：\n",
    "$$a_{ij} = \\frac{\\exp(<s_{i-1}, h_j>)}{\\sum_{k=1}^{T_x}\\exp(<s_{i-1}, h_k>)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "分为训练阶段和预测阶段:\n",
    "+ 预测的时候，每个lstm单元的输入包括上一个时刻的输出 和  注意力机制得到的context\n",
    "+ 训练的时候，每个lstm单元的输入包括上一个时刻的真实值 和 注意力机制得到的context\n",
    "\n",
    "context是上个时刻的输出状态和编码器状态计算得到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "核心在于attention机制,计算的输入包括两部分：\n",
    "+ 解码器$t$时刻的状态输出: `decoder_state_t: [1, batch_size, hidden_size]`\n",
    "+ 编码器的完整状态输出: `endoder_states: [batch_size, src_seq_len, hidden_szie]`\n",
    "\n",
    "计算的思路是先把 decoder_state_t 扩展为 和 endoder_states 维度相同的，然后于 endoder_states 逐元素相乘，再在dim=1维度求和，得到[batch_size, src_seq_len] 的矩阵，表示相似度矩阵。就可以再 dim=1 维度 进行softmax 操作。\n",
    "\n",
    "\n",
    "把 `decoder_state_t` 扩展为 和 `endoder_states` 维度相同的张量后，第二个维度表示的就是时间维度，只不过 `decoder_state_t` 每个时间的向量都是一样的。然后和 `endoder_states` 逐元素相乘，再在时间维度求和，其实就相当于 `decoder_state_t` 和 `endoder_states` 每个时刻的向量都做了内积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Seq2SeqEncoder, self).__init__()\n",
    "\n",
    "        self.lstm_layer = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            input_seq:[batch_size, seq_len, input_size]\n",
    "        return:\n",
    "            outputs: [batch_size, seq_len, hidden_size]，只包含状态 h\n",
    "            final_h: [1, batch_size, hidden_size]\n",
    "            final_c: [1, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        outputs, (final_h, final_c) = self.lstm_layer(input_seq)\n",
    "        return outputs, (final_h, final_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 12, 7]) torch.Size([1, 128, 7]) torch.Size([1, 128, 7])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "input_seq = torch.randn(128, 12, 3)\n",
    "encoder = Seq2SeqEncoder(3, 7)\n",
    "outputs, (final_h, final_c) = encoder(input_seq)\n",
    "print(outputs.shape, final_h.shape, final_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionMechanism(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Seq2SeqAttentionMechanism, self).__init__()\n",
    "\n",
    "    def forward(self, decoder_state_t, encoder_states):\n",
    "        \"\"\"\n",
    "        param:\n",
    "            decoder_state_t 解码器某一时刻的状态输出 [batch_size, hidden_size]\n",
    "            encoder_states: 编码器输出的各个状态 [batch_size, src_seq_len, hidden_size]\n",
    "        return:\n",
    "            context: 计算得到的加权求和 [batch_szie, hidden_size]\n",
    "            atten_prob:注意力分布 [batch_size, src_seq_len]\n",
    "        \"\"\"\n",
    "        batch_size, src_seq_len, hidden_size = encoder_states.shape\n",
    "\n",
    "        decoder_state_t = decoder_state_t.unsqueeze(dim=1) # 转为 batch_size, 1, hidden_size\n",
    "        decoder_state_t = torch.tile(decoder_state_t, dims=(1, src_seq_len, 1)) # 转为 batch_size, src_sen, hiddensize\n",
    "        # 计算 注意力分数\n",
    "        score = torch.sum(decoder_state_t * encoder_states, dim=-1) # [batch_size, src_seq_len]\n",
    "\n",
    "        atten_prob = torch.softmax(score, dim=1) # [batch_size, src_seq_len]\n",
    "        atten_prob = atten_prob.unsqueeze(-1) # [batch_size, src_seq_len, 1]\n",
    "        # 加权求和 :逐元素相乘，再在 序列长度维度求和\n",
    "        context = torch.sum(atten_prob * encoder_states, dim=1)  [batch_size, hidden_size]\n",
    "\n",
    "        return context, atten_prob.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # 因为每一步都要计算注意力分数，生成 新的状态，所以不能直接采用LSTM\n",
    "\n",
    "        self.lstm_cell = nn.LSTMCell(input_size + hidden_size, hidden_size)\n",
    "        self.attention_mechanism = Seq2SeqAttentionMechanism()\n",
    "\n",
    "    def forward(self, input_seq, target_seq, encoder_states, encoder_final_h_c):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            input_seq: [batch_size, src_seq_len, input_size ] 需要用最后一个时刻的值作为 解码器的初始\n",
    "            input_seq: [batch_size, tgt_seq_len, input_size ] 训练的时候是使用上一时刻真实值作为当前输入\n",
    "            encoder_states: [batch_size, src_seq_len, hidden_size] 编码器得到的向量\n",
    "            encoder_final_h_c:(h_t, c_t), [1, batch_size, hidden_size] 用做解码器的初始状态\n",
    "        return:\n",
    "            pred_outputs: [batch_size, tgt_seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        batch_size, tgt_seq_len, hidden_size = target_seq.shape\n",
    "        init_input_0 = input_seq[:, 0, :]\n",
    "        # 初始的 h c\n",
    "        h_t, c_t = encoder_final_h_c\n",
    "\n",
    "\n",
    "        pred_outpus = torch.zeros(size=(batch_size, tgt_seq_len, hidden_size))\n",
    "        for t in range(tgt_seq_len):\n",
    "            if t == 0:\n",
    "                decoder_input_t = input_seq[:, -1, :]\n",
    "            else:\n",
    "                decoder_input_t = target_seq[:, t-1, :]  # 使用真实值作为解码器输入\n",
    "            # 根据上一时刻的输出状态，计算新的输入\n",
    "            context, _ = self.attention_mechanism(h_t, encoder_states) # [batch_size, hidden_size]\n",
    "\n",
    "            decoder_input_t = torch.cat([decoder_input_t, context], dim=1) # [batch_size, input_size + hidden_size]\n",
    "\n",
    "            h_t, c_t = self.lstm_cell(decoder_input_t, (h_t, c_t))\n",
    "\n",
    "            # 将预测保存下来\n",
    "            pred_outpus[:, t, :] = h_t\n",
    "\n",
    "        return pred_outpus\n",
    "\n",
    "    def inference(self, input_seq, target_seq_len, encoder_states, encoder_final_h_c):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            input_seq: [batch_size, src_seq_len, input_size ] 需要用最后一个时刻的值作为 解码器的初始\n",
    "            target_seq_len: 预测序列的长度\n",
    "            encoder_states: [batch_size, src_seq_len, hidden_size] 编码器得到的向量\n",
    "            encoder_final_h_c:(h_t, c_t), [1, batch_size, hidden_size] 用做解码器的初始状态\n",
    "        return:\n",
    "            pred_outputs: [batch_size, tgt_seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        # 初始的 h c\n",
    "        h_t, c_t = encoder_final_h_c\n",
    "\n",
    "        batch_size, _, hidden_size = input_seq.shape\n",
    "        pred_outpus = torch.zeros(size=(batch_size, target_seq_len, hidden_size))\n",
    "        for t in range(target_seq_len):\n",
    "            if t == 0:\n",
    "                decoder_input_t = input_seq[:, -1, :]\n",
    "            else:\n",
    "                decoder_input_t = pred_outpus[:, t-1, :]  # 使用上一个输出作为 结果\n",
    "            # 根据上一时刻的输出状态，计算新的输入\n",
    "            context, _ = self.attention_mechanism(h_t, encoder_states) # [batch_size, hidden_size]\n",
    "            decoder_input_t = torch.cat([decoder_input_t, context], dim=1) # [batch_size, input_size + hidden_size]\n",
    "\n",
    "            # 计算当前时刻的状态\n",
    "            h_t, c_t = self.lstm_cell(decoder_input_t, (h_t, c_t))\n",
    "                \n",
    "            # 将预测保存下来\n",
    "            pred_outpus[:, t, :] = h_t\n",
    "\n",
    "        return pred_outpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Seq2SeqEncoder(input_size, hidden_size)\n",
    "        self.decoder = Seq2SeqDecoder(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, target_seq):\n",
    "        encoder_states, (final_h, final_c) = self.encoder(input_seq)\n",
    "        preds_outputs = self.decoder(input_seq, target_seq, encoder_states, (final_h, final_c))\n",
    "        return preds_outputs\n",
    "\n",
    "    def inference(self, input_seq, target_seq_len):\n",
    "        encoder_states, (final_h, final_c) = self.encoder(input_seq)\n",
    "        # 预测的时候是要使用 inference 函数\n",
    "        preds_outputs = self.decoder.inference(input_seq, target_seq_len, encoder_states, (final_h, final_c))\n",
    "        return preds_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07fac03186cb4872619664373be12749392d231b19ef18aa05ccb0afd9b23cee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
